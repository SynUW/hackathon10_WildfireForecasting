#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•æ¨¡å‹è®­ç»ƒè„šæœ¬ - smart_parallel.pyé€‚é…å™¨
æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼š--model, --type, --gpu, --log-dir
"""

import os
import sys

# åœ¨å¯¼å…¥ä»»ä½•å…¶ä»–æ¨¡å—ä¹‹å‰ä¿®å¤MKLå†²çª
os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'
os.environ['MKL_THREADING_LAYER'] = 'GNU'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'

# å…ˆå¯¼å…¥numpyæ¥åˆå§‹åŒ–MKL
import numpy as np

import argparse
import torch
import pandas as pd
from datetime import datetime

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å•æ¨¡å‹è®­ç»ƒè„šæœ¬')
    parser.add_argument('--model', type=str, required=True, help='æ¨¡å‹åç§°')
    parser.add_argument('--type', type=str, default='standard', choices=['standard', '10x'], help='æ¨¡å‹ç±»å‹')
    parser.add_argument('--gpu', type=int, default=0, help='GPUè®¾å¤‡å·')
    parser.add_argument('--log-dir', type=str, default='./trash/smart_parallel_logs_single_model', help='æ—¥å¿—ç›®å½•')
    return parser.parse_args()

def setup_environment(gpu_id):
    """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
    # è®¾ç½®CUDAè®¾å¤‡
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    
    # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ
    import time
    time.sleep(0.1)
    
    return True

def train_single_model_task(model_name, model_type, gpu_id, log_dir):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹ä»»åŠ¡"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒå•ä¸ªæ¨¡å‹: {model_name} ({model_type}) on GPU {gpu_id}")
    
    # è®¾ç½®ç¯å¢ƒï¼ˆåŒ…æ‹¬CUDA_VISIBLE_DEVICESï¼‰
    setup_environment(gpu_id)
    
    # å¯¼å…¥è®­ç»ƒç›¸å…³æ¨¡å—
    from train_all_models_combined import (
        set_seed, TRAINING_CONFIG, prepare_data_loaders, FIRMSNormalizer,
        DATA_CONFIG, train_single_model, test_model, save_structured_results_to_csv,
        worker_init_fn
    )
    from torch.utils.data import DataLoader
    
    # åˆå§‹åŒ–
    set_seed(TRAINING_CONFIG['seed'])
    
    # éªŒè¯GPUè®¾ç½®
    if torch.cuda.is_available():
        device = torch.device('cuda:0')  # ç”±äºè®¾ç½®äº†CUDA_VISIBLE_DEVICESï¼Œè¿™é‡Œæ€»æ˜¯0
        actual_gpu = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(actual_gpu)
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: Physical GPU {gpu_id} -> cuda:0 ({gpu_name})")
        
        # éªŒè¯GPUå†…å­˜
        gpu_memory = torch.cuda.get_device_properties(actual_gpu).total_memory / 1024**3
        print(f"ğŸ’¾ GPUå†…å­˜: {gpu_memory:.1f} GB")
    else:
        device = torch.device('cpu')
        print(f"âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        return False
    
    try:
        # å‡†å¤‡æ•°æ®
        print("ğŸ“‚ å‡†å¤‡æ•°æ®...")
        train_dataset, val_dataset, test_dataset, data_loader_obj = prepare_data_loaders()
        
        # åˆå§‹åŒ–FIRMSå½’ä¸€åŒ–å™¨
        print("ğŸ”§ åˆå§‹åŒ–FIRMSå½’ä¸€åŒ–å™¨...")
        firms_normalizer = FIRMSNormalizer(
            method='log1p_minmax',
            firms_min=DATA_CONFIG['firms_min'],
            firms_max=DATA_CONFIG['firms_max']
        )
        
        # ä¸ºå½’ä¸€åŒ–æ‹Ÿåˆåˆ›å»ºä¸´æ—¶æ•°æ®åŠ è½½å™¨ï¼ˆå‡å°‘workeræ•°é‡ï¼Œåªç”¨äºå¿«é€Ÿæ‹Ÿåˆï¼‰
        temp_loader = DataLoader(
            train_dataset, batch_size=1024, shuffle=False,  # å¢å¤§batch_sizeåŠ å¿«æ‹Ÿåˆ
            num_workers=1, collate_fn=data_loader_obj.dataset.custom_collate_fn  # å‡å°‘workeré¿å…å†…å­˜å†²çª
        )
        firms_normalizer.fit(temp_loader)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä¼˜åŒ–æ€§èƒ½è®¾ç½®ï¼‰
        config_key = model_type
        train_config = TRAINING_CONFIG[config_key]
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´workeræ•°é‡ï¼Œé¿å…è¿‡å¤šè¿›ç¨‹ç«äº‰
        if model_type == '10x':
            train_workers = 4  # 10xæ¨¡å‹ä½¿ç”¨æ›´å¤šworkers
            val_workers = 2
            test_workers = 2
        else:
            train_workers = 6  # æ ‡å‡†æ¨¡å‹å¯ä»¥ä½¿ç”¨æ›´å¤šworkers
            val_workers = 4
            test_workers = 4
        
        train_loader = DataLoader(
            train_dataset, batch_size=train_config['batch_size'], shuffle=True, 
            num_workers=train_workers, collate_fn=data_loader_obj.dataset.custom_collate_fn, 
            worker_init_fn=worker_init_fn, pin_memory=True, persistent_workers=True  # ä¼˜åŒ–è®¾ç½®
        )
        val_loader = DataLoader(
            val_dataset, batch_size=train_config['batch_size'], shuffle=False,
            num_workers=val_workers, collate_fn=data_loader_obj.dataset.custom_collate_fn, 
            worker_init_fn=worker_init_fn, pin_memory=True, persistent_workers=True  # ä¼˜åŒ–è®¾ç½®
        )
        test_loader = DataLoader(
            test_dataset, batch_size=train_config['batch_size'], shuffle=False,
            num_workers=test_workers, collate_fn=data_loader_obj.dataset.custom_collate_fn, 
            worker_init_fn=worker_init_fn, pin_memory=True, persistent_workers=True  # ä¼˜åŒ–è®¾ç½®
        )
        
        # è®­ç»ƒæ¨¡å‹
        print(f"ğŸ”¥ å¼€å§‹è®­ç»ƒ {model_name}...")
        result = train_single_model(
            model_name, device, train_loader, val_loader, test_loader, firms_normalizer, model_type
        )
        
        if result is None:
            print(f"âŒ {model_name} ({model_type}) è®­ç»ƒå¤±è´¥")
            return False
        
        print(f"âœ… {model_name} ({model_type}) è®­ç»ƒå®Œæˆ")
        
        # æµ‹è¯•æ‰€æœ‰ä¿å­˜çš„æ¨¡å‹
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯• {model_name} çš„æ‰€æœ‰ä¿å­˜æ¨¡å‹...")
        
        # ç”¨äºå­˜å‚¨ç»“æ„åŒ–æµ‹è¯•ç»“æœçš„å­—å…¸
        structured_results = {model_name: {
            'f1': {'precision': None, 'recall': None, 'f1': None, 'pr_auc': None, 'mse': None, 'mae': None},
            'recall': {'precision': None, 'recall': None, 'f1': None, 'pr_auc': None, 'mse': None, 'mae': None},
            'pr_auc': {'precision': None, 'recall': None, 'f1': None, 'pr_auc': None, 'mse': None, 'mae': None},
            'mae': {'precision': None, 'recall': None, 'f1': None, 'pr_auc': None, 'mse': None, 'mae': None},
            'mse': {'precision': None, 'recall': None, 'f1': None, 'pr_auc': None, 'mse': None, 'mae': None},
            'final_epoch': {'precision': None, 'recall': None, 'f1': None, 'pr_auc': None, 'mse': None, 'mae': None}
        }}
        
        # æµ‹è¯•å„ä¸ªæœ€ä½³æ¨¡å‹å’Œæœ€åepochæ¨¡å‹
        for metric_name, metric_info in result.items():
            if metric_info['path'] is not None:
                if metric_name == 'final_epoch':
                    print(f"ğŸ“Š æµ‹è¯• final_epoch æ¨¡å‹...")
                else:
                    print(f"ğŸ“Š æµ‹è¯• {metric_name} æ¨¡å‹...")
                
                try:
                    test_result = test_model(model_name, metric_info['path'], device, test_loader, firms_normalizer, model_type)
                    if test_result:
                        # ä¿å­˜åˆ°ç»“æ„åŒ–ç»“æœä¸­
                        structured_results[model_name][metric_name] = {
                            'precision': test_result['precision'],
                            'recall': test_result['recall'],
                            'f1': test_result['f1'],
                            'pr_auc': test_result['pr_auc'],
                            'mse': test_result['mse'],
                            'mae': test_result['mae']
                        }
                        print(f"   P={test_result['precision']:.4f}, R={test_result['recall']:.4f}, F1={test_result['f1']:.4f}, PR-AUC={test_result['pr_auc']:.4f}, MSE={test_result['mse']:.6f}, MAE={test_result['mae']:.6f}")
                except Exception as e:
                    print(f"âŒ {model_name} ({metric_name}) æµ‹è¯•å¤±è´¥: {str(e)}")
        
        # ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
        print(f"ğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ...")
        
        # å‡†å¤‡CSVæ•°æ®
        csv_data = []
        columns = ['Model']
        metric_types = ['f1', 'recall', 'pr_auc', 'mae', 'mse', 'final_epoch']
        metric_names = ['precision', 'recall', 'f1', 'pr_auc', 'mse', 'mae']
        
        for metric_type in metric_types:
            for metric_name in metric_names:
                display_type = "final_epoch" if metric_type == 'final_epoch' else f"best_{metric_type}"
                columns.append(f"{display_type}_{metric_name}")
        
        # æ·»åŠ æ•°æ®è¡Œ
        row = [model_name]
        for metric_type in metric_types:
            for metric_name in metric_names:
                value = structured_results[model_name][metric_type][metric_name]
                if value is not None:
                    row.append(f"{value:.6f}")
                else:
                    row.append("N/A")
        csv_data.append(row)
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶
        df = pd.DataFrame(csv_data, columns=columns)
        csv_filename = os.path.join(log_dir, f"{model_name}_{model_type}_results.csv")
        df.to_csv(csv_filename, index=False)
        
        # ä¿å­˜æ‘˜è¦æ–‡ä»¶
        summary_filename = os.path.join(log_dir, f"{model_name}_{model_type}_summary.txt")
        with open(summary_filename, 'w', encoding='utf-8') as f:
            f.write(f"æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•æ‘˜è¦ - {model_name} ({model_type})\n")
            f.write(f"{'='*60}\n")
            f.write(f"è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"GPUè®¾å¤‡: {gpu_id}\n\n")
            
            f.write("æµ‹è¯•ç»“æœ:\n")
            f.write("-" * 40 + "\n")
            for metric_type in metric_types:
                metrics = structured_results[model_name][metric_type]
                if metrics['precision'] is not None:
                    display_type = "FINAL" if metric_type == 'final_epoch' else metric_type.upper()
                    f.write(f"{display_type:<12} P={metrics['precision']:<8.4f} R={metrics['recall']:<8.4f} F1={metrics['f1']:<8.4f} PR-AUC={metrics['pr_auc']:<8.4f} MSE={metrics['mse']:<10.6f} MAE={metrics['mae']:<10.6f}\n")
        
        print(f"ğŸ“„ ç»“æœæ‘˜è¦å·²ä¿å­˜: {summary_filename}")
        print(f"ğŸ‰ {model_name} ({model_type}) è®­ç»ƒå’Œæµ‹è¯•å®Œæˆ!")
        
        return True
        
    except Exception as e:
        print(f"ğŸ’¥ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    print(f"ğŸ”¥ å•æ¨¡å‹è®­ç»ƒå™¨")
    print(f"ğŸ“‹ æ¨¡å‹: {args.model}")
    print(f"ğŸ“‹ ç±»å‹: {args.type}")
    print(f"ğŸ“‹ GPU: {args.gpu}")
    print(f"ğŸ“‹ æ—¥å¿—ç›®å½•: {args.log_dir}")
    print("=" * 50)
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(args.log_dir, exist_ok=True)
    
    # è®¾ç½®ç¯å¢ƒå¹¶è®­ç»ƒæ¨¡å‹
    success = train_single_model_task(args.model, args.type, args.gpu, args.log_dir)
    
    if success:
        print("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!")
        sys.exit(0)
    else:
        print("âŒ è®­ç»ƒå¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main() 