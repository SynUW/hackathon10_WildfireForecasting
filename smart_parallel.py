#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å¹¶è¡Œè®­ç»ƒå™¨ - ç®€åŒ–ç‰ˆ
è‡ªåŠ¨ç›‘æµ‹æ¨¡å‹å®ŒæˆçŠ¶æ€ï¼Œæ™ºèƒ½å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡
"""

import subprocess
import time
import os
import signal
import sys
from datetime import datetime
import pandas as pd
import argparse

# =============================================================================
# é…ç½®å‚æ•°
# =============================================================================

# å¯¼å…¥é…ç½®å‚æ•°
from train_all_models_combined import (
    ENABLE_10X_TRAINING, 
    DEFAULT_MAX_PARALLEL_PER_GPU,
    get_all_models,
    is_model_trained,  # æ·»åŠ æ–­ç‚¹ç»­ä¼ å‡½æ•°
    filter_trained_models  # æ·»åŠ æ–­ç‚¹ç»­ä¼ å‡½æ•°
)

class SmartParallelTrainer:
    """æ™ºèƒ½å¹¶è¡Œè®­ç»ƒå™¨"""
    
    def __init__(self, max_parallel_per_gpu=2):
        self.max_parallel_per_gpu = max_parallel_per_gpu
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—ç›®å½•
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.log_dir = f"./trash/smart_parallel_logs_{timestamp}"
        self.running_tasks = {}  # {task_id: task_info}
        self.completed_tasks = []
        self.failed_tasks = []
        self.task_queue = []
        self.gpu_counts = {0: 0, 1: 0}  # GPUä»»åŠ¡è®¡æ•°
        self.task_counter = 0
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(self.log_dir, exist_ok=True)
        print(f"ğŸ“ æ—¥å¿—ç›®å½•: {self.log_dir}")
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.stop_all)
        signal.signal(signal.SIGTERM, self.stop_all)
    
    def add_tasks(self, model_configs):
        """æ·»åŠ è®­ç»ƒä»»åŠ¡"""
        for config in model_configs:
            task = {
                'model': config['model'],
                'type': config.get('type', 'standard'),
                'gpu': config.get('gpu', 0),
                'id': f"task_{self.task_counter}",
                'status': 'pending'
            }
            self.task_queue.append(task)
            self.task_counter += 1
            print(f"ğŸ“‹ æ·»åŠ ä»»åŠ¡: {task['model']}({task['type']}) -> GPU{task['gpu']}")
    
    def get_available_gpu(self, preferred_gpu):
        """è·å–å¯ç”¨çš„GPU"""
        # å…ˆæ£€æŸ¥é¦–é€‰GPU
        if self.gpu_counts[preferred_gpu] < self.max_parallel_per_gpu:
            return preferred_gpu
        
        # æ£€æŸ¥å…¶ä»–GPU
        for gpu_id in [0, 1]:
            if self.gpu_counts[gpu_id] < self.max_parallel_per_gpu:
                return gpu_id
        
        return None
    
    def start_task(self, task):
        """å¯åŠ¨å•ä¸ªä»»åŠ¡"""
        available_gpu = self.get_available_gpu(task['gpu'])
        if available_gpu is None:
            return False
        
        task['gpu'] = available_gpu  # å¯èƒ½é‡æ–°åˆ†é…GPU
        
        # å‡†å¤‡å‘½ä»¤
        cmd = [
            "python", "train_single_model.py",
            "--model", task['model'],
            "--type", task['type'],
            "--gpu", str(task['gpu']),
            "--log-dir", self.log_dir
        ]
        
        # æ—¥å¿—æ–‡ä»¶
        log_file = os.path.join(self.log_dir, f"{task['model']}_{task['type']}_gpu{task['gpu']}.log")
        
        try:
            # å¯åŠ¨è¿›ç¨‹
            with open(log_file, 'w') as f:
                process = subprocess.Popen(cmd, stdout=f, stderr=subprocess.STDOUT)
            
            # è®°å½•ä»»åŠ¡ä¿¡æ¯
            task.update({
                'process': process,
                'pid': process.pid,
                'start_time': datetime.now(),
                'log_file': log_file,
                'status': 'running'
            })
            
            self.running_tasks[task['id']] = task
            self.gpu_counts[task['gpu']] += 1
            
            print(f"ğŸš€ å¯åŠ¨: {task['model']}({task['type']}) on GPU{task['gpu']} (PID: {task['pid']})")
            return True
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨å¤±è´¥: {task['model']} - {e}")
            return False
    
    def check_completed_tasks(self):
        """æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡"""
        completed_ids = []
        
        for task_id, task in self.running_tasks.items():
            return_code = task['process'].poll()
            if return_code is not None:
                # ä»»åŠ¡å®Œæˆ
                end_time = datetime.now()
                duration = end_time - task['start_time']
                
                # æ›´æ–°GPUè®¡æ•°
                self.gpu_counts[task['gpu']] -= 1
                
                if return_code == 0:
                    task['status'] = 'completed'
                    self.completed_tasks.append(task)
                    print(f"âœ… å®Œæˆ: {task['model']}({task['type']}) è€—æ—¶: {duration}")
                else:
                    task['status'] = 'failed'
                    self.failed_tasks.append(task)
                    print(f"âŒ å¤±è´¥: {task['model']}({task['type']}) è¿”å›ç : {return_code}")
                
                completed_ids.append(task_id)
        
        # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
        for task_id in completed_ids:
            del self.running_tasks[task_id]
    
    def start_pending_tasks(self):
        """å¯åŠ¨ç­‰å¾…ä¸­çš„ä»»åŠ¡"""
        started_count = 0
        remaining_tasks = []
        
        for task in self.task_queue:
            if task['status'] == 'pending':
                if self.start_task(task):
                    started_count += 1
                else:
                    remaining_tasks.append(task)
            else:
                remaining_tasks.append(task)
        
        self.task_queue = remaining_tasks
        return started_count
    
    def print_status(self):
        """æ‰“å°çŠ¶æ€"""
        pending = len([t for t in self.task_queue if t['status'] == 'pending'])
        running = len(self.running_tasks)
        completed = len(self.completed_tasks)
        failed = len(self.failed_tasks)
        
        print(f"\rğŸ“Š ç­‰å¾…({pending}) è¿è¡Œ({running}) å®Œæˆ({completed}) å¤±è´¥({failed}) | "
              f"GPU0: {self.gpu_counts[0]}/{self.max_parallel_per_gpu} "
              f"GPU1: {self.gpu_counts[1]}/{self.max_parallel_per_gpu}", end="", flush=True)
    
    def run(self):
        """è¿è¡Œè®­ç»ƒé˜Ÿåˆ—"""
        print(f"ğŸš€ æ™ºèƒ½å¹¶è¡Œè®­ç»ƒå™¨å¯åŠ¨")
        print(f"ğŸ“‹ æ€»ä»»åŠ¡æ•°: {len(self.task_queue)}")
        print(f"âš™ï¸ æ¯GPUæœ€å¤§å¹¶è¡Œ: {self.max_parallel_per_gpu}")
        print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢æ‰€æœ‰ä»»åŠ¡\n")
        
        try:
            while True:
                # æ£€æŸ¥å®Œæˆçš„ä»»åŠ¡
                self.check_completed_tasks()
                
                # å¯åŠ¨æ–°ä»»åŠ¡
                self.start_pending_tasks()
                
                # æ‰“å°çŠ¶æ€
                self.print_status()
                
                # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆ
                if (len(self.task_queue) == 0 and 
                    len(self.running_tasks) == 0 and 
                    (len(self.completed_tasks) + len(self.failed_tasks)) > 0):
                    break
                
                time.sleep(15)  # æ¯15ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œå‡å°‘æ£€æŸ¥é¢‘ç‡
            
            print(f"\n\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
            self.print_summary()
            
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·...")
            self.stop_all()
    
    def stop_all(self, signum=None, frame=None):
        """åœæ­¢æ‰€æœ‰ä»»åŠ¡"""
        print(f"\nğŸ›‘ åœæ­¢æ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡...")
        
        for task in self.running_tasks.values():
            try:
                task['process'].terminate()
                print(f"ğŸ›‘ åœæ­¢: {task['model']}({task['type']})")
            except:
                pass
        
        # ç­‰å¾…è¿›ç¨‹ç»“æŸ
        time.sleep(2)
        
        # å¼ºåˆ¶æ€æ­»
        for task in self.running_tasks.values():
            try:
                task['process'].kill()
            except:
                pass
        
        if signum:
            sys.exit(0)
    
    def test_completed_models(self):
        """æ”¶é›†å¹¶æ±‡æ€»æ‰€æœ‰æˆåŠŸå®Œæˆçš„æ¨¡å‹çš„æµ‹è¯•ç»“æœ"""
        if not self.completed_tasks:
            print("âš ï¸ æ²¡æœ‰æˆåŠŸå®Œæˆçš„æ¨¡å‹éœ€è¦æ”¶é›†ç»“æœ")
            return
            
        print(f"\nğŸ“Š æ”¶é›† {len(self.completed_tasks)} ä¸ªå·²å®Œæˆæ¨¡å‹çš„æµ‹è¯•ç»“æœ...")
        
        # åˆ†åˆ«æ”¶é›†æ ‡å‡†æ¨¡å‹å’Œ10xæ¨¡å‹çš„ç»“æœ
        standard_results = {}
        tenx_results = {}
        
        for task in self.completed_tasks:
            model_name = task['model']
            model_type = task['type']
            
            # æ£€æŸ¥å¯¹åº”çš„CSVç»“æœæ–‡ä»¶
            csv_file = os.path.join(self.log_dir, f"{model_name}_{model_type}_results.csv")
            
            if os.path.exists(csv_file):
                try:
                    import pandas as pd
                    df = pd.read_csv(csv_file)
                    
                    if len(df) > 0:
                        # å°†DataFrameè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                        row = df.iloc[0]
                        model_result = {
                            'f1': {
                                'precision': self._safe_float(row.get('best_f1_precision')),
                                'recall': self._safe_float(row.get('best_f1_recall')),
                                'f1': self._safe_float(row.get('best_f1_f1')),
                                'pr_auc': self._safe_float(row.get('best_f1_pr_auc'))
                            },
                            'recall': {
                                'precision': self._safe_float(row.get('best_recall_precision')),
                                'recall': self._safe_float(row.get('best_recall_recall')),
                                'f1': self._safe_float(row.get('best_recall_f1')),
                                'pr_auc': self._safe_float(row.get('best_recall_pr_auc'))
                            },
                            'pr_auc': {
                                'precision': self._safe_float(row.get('best_pr_auc_precision')),
                                'recall': self._safe_float(row.get('best_pr_auc_recall')),
                                'f1': self._safe_float(row.get('best_pr_auc_f1')),
                                'pr_auc': self._safe_float(row.get('best_pr_auc_pr_auc'))
                            },
                            'final_epoch': {
                                'precision': self._safe_float(row.get('final_epoch_precision')),
                                'recall': self._safe_float(row.get('final_epoch_recall')),
                                'f1': self._safe_float(row.get('final_epoch_f1')),
                                'pr_auc': self._safe_float(row.get('final_epoch_pr_auc'))
                            }
                        }
                        
                        if model_type == 'standard':
                            standard_results[model_name] = model_result
                        else:
                            tenx_results[model_name] = model_result
                        
                        print(f"âœ… æ”¶é›† {model_name}({model_type}) çš„æµ‹è¯•ç»“æœ")
                    else:
                        print(f"âš ï¸ {model_name}({model_type}) çš„CSVæ–‡ä»¶ä¸ºç©º")
                        
                except Exception as e:
                    print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
            else:
                print(f"âŒ æœªæ‰¾åˆ°CSVç»“æœæ–‡ä»¶: {csv_file}")
        
        # ç”Ÿæˆæ±‡æ€»çš„CSVæ–‡ä»¶
        if standard_results:
            self._save_combined_csv(standard_results, 'standard')
        if tenx_results:
            self._save_combined_csv(tenx_results, '10x')
        
        print(f"\nğŸ“Š ç»“æœæ”¶é›†å®Œæˆ!")
        print(f"   æ ‡å‡†æ¨¡å‹: {len(standard_results)} ä¸ª")
        print(f"   10xæ¨¡å‹: {len(tenx_results)} ä¸ª")
        
        return len(standard_results) + len(tenx_results)
    
    def _safe_float(self, value):
        """å®‰å…¨åœ°è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œå¤„ç†N/Aå€¼"""
        if pd.isna(value) or value == 'N/A':
            return None
        try:
            return float(value)
        except:
            return None
    
    def _save_combined_csv(self, results, model_type):
        """ä¿å­˜åˆå¹¶çš„CSVç»“æœ"""
        if not results:
            return
        
        # å‡†å¤‡CSVæ•°æ®
        csv_data = []
        
        # CSVåˆ—å
        columns = ['Model']
        metric_types = ['f1', 'recall', 'pr_auc', 'final_epoch']
        metric_names = ['precision', 'recall', 'f1', 'pr_auc']
        
        for metric_type in metric_types:
            for metric_name in metric_names:
                display_type = "final_epoch" if metric_type == 'final_epoch' else f"best_{metric_type}"
                columns.append(f"{display_type}_{metric_name}")
        
        # æ·»åŠ æ•°æ®è¡Œ
        for model_name, model_results in results.items():
            row = [model_name]
            
            for metric_type in metric_types:
                for metric_name in metric_names:
                    value = model_results[metric_type][metric_name]
                    if value is not None:
                        row.append(f"{value:.6f}")
                    else:
                        row.append("N/A")
            
            csv_data.append(row)
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶
        import pandas as pd
        df = pd.DataFrame(csv_data, columns=columns)
        
        csv_filename = f"combined_results_{model_type}.csv"
        csv_path = os.path.join(self.log_dir, csv_filename)
        df.to_csv(csv_path, index=False)
        
        print(f"ğŸ“Š {model_type}æ¨¡å‹æ±‡æ€»ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
        print(f"   å…±åŒ…å« {len(csv_data)} ä¸ªæ¨¡å‹çš„æµ‹è¯•ç»“æœ")
        print(f"   CSVæ ¼å¼: æ¨¡å‹å + 4ç§ä¿å­˜ç‰ˆæœ¬ Ã— 4ä¸ªæŒ‡æ ‡ = {len(columns)} åˆ—")
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        total = len(self.completed_tasks) + len(self.failed_tasks)
        success_rate = len(self.completed_tasks) / total * 100 if total > 0 else 0
        
        print(f"ğŸ“Š æ‰§è¡Œæ‘˜è¦:")
        print(f"   æ€»ä»»åŠ¡: {total}")
        print(f"   æˆåŠŸ: {len(self.completed_tasks)}")
        print(f"   å¤±è´¥: {len(self.failed_tasks)}")
        print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        
        if self.completed_tasks:
            print(f"\nâœ… æˆåŠŸå®Œæˆçš„æ¨¡å‹:")
            for task in self.completed_tasks:
                duration = task.get('end_time', datetime.now()) - task['start_time']
                print(f"   {task['model']}({task['type']}) - {duration}")
        
        if self.failed_tasks:
            print(f"\nâŒ å¤±è´¥çš„æ¨¡å‹:")
            for task in self.failed_tasks:
                print(f"   {task['model']}({task['type']})")
        
        # è‡ªåŠ¨æµ‹è¯•å®Œæˆçš„æ¨¡å‹
        if self.completed_tasks:
            self.test_completed_models()

def get_all_available_models():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¿‡æ»¤æ‰æ— æ³•åŠ è½½çš„æ¨¡å‹"""
    # ä½¿ç”¨train_all_models_combined.pyä¸­çš„å‡½æ•°è·å–æ¨¡å‹åˆ—è¡¨
    models = get_all_models('model_zoo')
    
    # è¿‡æ»¤æ‰éœ€è¦ç‰¹æ®Šä¾èµ–çš„æ¨¡å‹
    available_models = []
    for model_name in models:
        if model_name == 'Mamba':
            try:
                import mamba_ssm
                available_models.append(model_name)
                print(f"âœ… {model_name} å¯ç”¨ (mamba_ssmå·²å®‰è£…)")
            except ImportError:
                print(f"âš ï¸ è·³è¿‡ {model_name} (ç¼ºå°‘mamba_ssmåº“)")
                continue
        else:
            available_models.append(model_name)
    
    return sorted(available_models)

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='æ™ºèƒ½å¹¶è¡Œè®­ç»ƒå™¨')
    parser.add_argument('--skip-10x', action='store_true', 
                       help='è·³è¿‡10xæ¨¡å‹è®­ç»ƒï¼Œåªè®­ç»ƒæ ‡å‡†æ¨¡å‹')
    parser.add_argument('--only-10x', action='store_true',
                       help='åªè®­ç»ƒ10xæ¨¡å‹ï¼Œè·³è¿‡æ ‡å‡†æ¨¡å‹')
    parser.add_argument('--max-parallel', type=int, default=DEFAULT_MAX_PARALLEL_PER_GPU,
                       help=f'æ¯ä¸ªGPUçš„æœ€å¤§å¹¶è¡Œä»»åŠ¡æ•° (é»˜è®¤: {DEFAULT_MAX_PARALLEL_PER_GPU})')
    parser.add_argument('--models', nargs='+',
                       help='æŒ‡å®šè¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨ (å¦‚æœä¸æŒ‡å®šåˆ™è®­ç»ƒæ‰€æœ‰æ¨¡å‹)')
    parser.add_argument('--force-retrain', action='store_true',
                       help='å¼ºåˆ¶é‡æ–°è®­ç»ƒæ‰€æœ‰æ¨¡å‹ï¼Œå¿½ç•¥å·²å­˜åœ¨çš„æ¨¡å‹æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("ğŸš€ æ™ºèƒ½å¹¶è¡Œè®­ç»ƒå™¨")
    print("ğŸ’¡ æ”¯æŒè‡ªåŠ¨è·³è¿‡å·²è®­ç»ƒå®Œæˆçš„æ¨¡å‹ (æ£€æŸ¥final_epoch.pthæ–‡ä»¶)")
    print("   ä½¿ç”¨ --force-retrain å¯å¼ºåˆ¶é‡æ–°è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    print()
    
    # æ˜¾ç¤ºé…ç½®çŠ¶æ€
    from train_all_models_combined import print_config_status
    print_config_status()
    print()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SmartParallelTrainer(max_parallel_per_gpu=args.max_parallel)
    
    # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
    all_models = get_all_available_models()
    
    # å¦‚æœæŒ‡å®šäº†ç‰¹å®šæ¨¡å‹ï¼Œåˆ™åªä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
    if args.models:
        specified_models = [m for m in args.models if m in all_models]
        missing_models = [m for m in args.models if m not in all_models]
        if missing_models:
            print(f"âš ï¸ ä»¥ä¸‹æ¨¡å‹ä¸å¯ç”¨: {', '.join(missing_models)}")
        all_models = specified_models
    
    print(f"ğŸ” å‘ç° {len(all_models)} ä¸ªå¯ç”¨æ¨¡å‹: {', '.join(all_models)}")
    
    # æ ¹æ®é…ç½®å’Œå‘½ä»¤è¡Œå‚æ•°å†³å®šè®­ç»ƒå“ªäº›æ¨¡å‹
    train_standard = not args.only_10x
    train_10x = ENABLE_10X_TRAINING and not args.skip_10x
    
    if args.skip_10x:
        print("ğŸ“‹ å·²é€‰æ‹©è·³è¿‡10xæ¨¡å‹è®­ç»ƒ")
        train_10x = False
    elif args.only_10x:
        print("ğŸ“‹ å·²é€‰æ‹©åªè®­ç»ƒ10xæ¨¡å‹")
        train_standard = False
    elif not ENABLE_10X_TRAINING:
        print("âš ï¸ 10xæ¨¡å‹è®­ç»ƒå·²åœ¨é…ç½®ä¸­ç¦ç”¨")
        train_10x = False
    
    print(f"ğŸ“‹ è®­ç»ƒè®¡åˆ’: æ ‡å‡†æ¨¡å‹={'âœ…' if train_standard else 'âŒ'}, 10xæ¨¡å‹={'âœ…' if train_10x else 'âŒ'}")
    
    # ç”Ÿæˆæ¨¡å‹é…ç½®
    model_configs = []
    
    # ç¬¬ä¸€æ‰¹ï¼šæ ¸å¿ƒæ¨¡å‹ï¼ˆä¼˜å…ˆè®­ç»ƒï¼‰
    priority_models = ["DLinear", "CrossLinear", "iTransformer", "s_mamba"]
    
    # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
    models_to_train_standard = []
    models_to_train_10x = []
    total_skipped = 0
    
    # æ·»åŠ æ ‡å‡†æ¨¡å‹ - ä½¿ç”¨æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
    if train_standard:
        # è¿‡æ»¤å·²è®­ç»ƒçš„æ ‡å‡†æ¨¡å‹
        models_to_train_standard, trained_models_standard = filter_trained_models(all_models, 'standard', force_retrain=args.force_retrain)
        
        # æ·»åŠ ä¼˜å…ˆæ¨¡å‹
        for i, model in enumerate(priority_models):
            if model in models_to_train_standard:
                model_configs.append({
                    "model": model,
                    "type": "standard", 
                    "gpu": i % 2,  # è½®æµåˆ†é…GPU
                    "priority": 1
                })
        
        # æ·»åŠ å…¶ä»–æ ‡å‡†æ¨¡å‹
        other_models = [m for m in models_to_train_standard if m not in priority_models]
        for i, model in enumerate(other_models):
            model_configs.append({
                "model": model,
                "type": "standard",
                "gpu": i % 2,  # è½®æµåˆ†é…GPU
                "priority": 2
            })
    
    # æ·»åŠ 10xæ¨¡å‹ - ä½¿ç”¨æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
    if train_10x:
        # è¿‡æ»¤å·²è®­ç»ƒçš„10xæ¨¡å‹
        models_to_train_10x, trained_models_10x = filter_trained_models(all_models, '10x', force_retrain=args.force_retrain)
        
        for i, model in enumerate(models_to_train_10x):
            model_configs.append({
                "model": model,
                "type": "10x",
                "gpu": i % 2,  # è½®æµåˆ†é…GPU
                "priority": 3
            })
    
    print(f"ğŸ“‹ æ€»å…±é…ç½®äº† {len(model_configs)} ä¸ªè®­ç»ƒä»»åŠ¡")
    
    # ç»Ÿè®¡ä¿¡æ¯
    if train_standard:
        standard_count = len([c for c in model_configs if c['type'] == 'standard'])
        skipped_standard = len(all_models) - len(models_to_train_standard)
        total_skipped += skipped_standard
        print(f"   æ ‡å‡†æ¨¡å‹: {standard_count} ä¸ªå¾…è®­ç»ƒ, {skipped_standard} ä¸ªå·²å®Œæˆ")
    if train_10x:
        tenx_count = len([c for c in model_configs if c['type'] == '10x'])
        skipped_10x = len(all_models) - len(models_to_train_10x)
        total_skipped += skipped_10x
        print(f"   10xæ¨¡å‹: {tenx_count} ä¸ªå¾…è®­ç»ƒ, {skipped_10x} ä¸ªå·²å®Œæˆ")
    
    if total_skipped > 0 and not args.force_retrain:
        print(f"ğŸ’¡ æ€»å…±è·³è¿‡ {total_skipped} ä¸ªå·²è®­ç»ƒæ¨¡å‹ (ä½¿ç”¨ --force-retrain å¯å¼ºåˆ¶é‡æ–°è®­ç»ƒ)")
    elif args.force_retrain:
        print(f"ğŸ”„ å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å¼ï¼šå°†è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    
    if not model_configs:
        print("âŒ æ²¡æœ‰å¯è®­ç»ƒçš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    # æ·»åŠ ä»»åŠ¡å¹¶è¿è¡Œ
    trainer.add_tasks(model_configs)
    trainer.run()

if __name__ == "__main__":
    main() 